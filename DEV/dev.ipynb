{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea66ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from loguru import logger \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6365ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_PATH = \"/quotes_db.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_db(df: pd.DataFrame):\n",
    "    df.to_csv(CSV_FILE_PATH, index=True, index_label='id')\n",
    "\n",
    "def read_db()->pd.DataFrame:\n",
    "    df = pd.read_csv(CSV_FILE_PATH, index_cols='id')\n",
    "    return df\n",
    "\n",
    "def initialize_db():\n",
    "    df = pd.DataFrame(columns=['id', 'text'])\n",
    "    df = df.set_index('id')\n",
    "    write_db(df)\n",
    "\n",
    "\n",
    "initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe89128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tototata'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"toto\" + \"tata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81897b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend/modules/df_tools.py\n",
    "from loguru import logger \n",
    "import pandas as pd\n",
    "import os \n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker, session\n",
    "\n",
    "\n",
    "DB_FILE_PATH = os.path.join(os.getcwd(),\"quotes_db.sql\")\n",
    "engine = create_engine(f\"sqlite:///{DB_FILE_PATH}\", echo=False)\n",
    "session_locale = sessionmaker(bind=engine, autoflush=False, autocommit=False)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "\n",
    "#CSV_FILE_PATH = os.path.join(\"backend\",\"data\", \"quotes_db.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca7f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quote(Base):\n",
    "    __tablename__ = \"quotes\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    text = Column(String, nullable=False)\n",
    "\n",
    "TABLE_NAME = \"quotes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b97c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    return session_locale() # permet de créer une session quand on en a besoin\n",
    "\n",
    "def write_db(df: pd.DataFrame):\n",
    "    #df.to_csv(CSV_FILE_PATH, index=True, index_label='id')\n",
    "    #print(\"write_df\\n\", df)\n",
    "    df.to_sql(\n",
    "        TABLE_NAME,\n",
    "        con=engine,\n",
    "        if_exists='replace', # supprime et remplace la db si deja existante avec la nouvelle db modifiée\n",
    "        index=True,\n",
    "        index_label='id'\n",
    "    )\n",
    "\n",
    "def read_db()->pd.DataFrame:\n",
    "    # df = pd.read_csv(CSV_FILE_PATH, index_col='id')\n",
    "\n",
    "    # if df.isnull().any().any():\n",
    "    #     # raise ValueError(\"Le CSV contient des valeurs nulles\")\n",
    "    #     df_clean = df.dropna()\n",
    "    # for r, c in df.iterrows():\n",
    "    #     print(c.text.isempty)\n",
    "    with get_session() as session:\n",
    "        quotes = session.query(Quote).all() # la liste des objets Quote\n",
    "\n",
    "    # on veut transformer en dataframe comme dans df_tools \n",
    "    # on parcout la liste quotes\n",
    "    data = [{\"id\": q.id, \"text\": q.text} for q in quotes]\n",
    "    \n",
    "    if not data:\n",
    "        # cas index vide pris en compte\n",
    "        return pd.DataFrame(columns=[\"text\"])\n",
    "    \n",
    "    df = pd.DataFrame(data).set_index(\"id\")\n",
    "\n",
    "    # nettoayge NAN comme dans \n",
    "    for index, row in df.iterrows() : \n",
    "        for col in df.columns:\n",
    "            if pd.isna(row[col]):\n",
    "                logger.info(f\"NaN trouvé à la ligne {index}, colonne '{col}' remplacé par la valeur 'NULL'\")\n",
    "                df.loc[index, col] = \"NULL_REPLACEMENT_VALUE\"\n",
    "    \n",
    "    # print(\"DATA =\", data)\n",
    "    # print(\"COLUMNS =\", df.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "def initialize_db():\n",
    "    # if os.path.exists(CSV_FILE_PATH):\n",
    "    #     logger.info(\"La base de données existe\")\n",
    "    # else:\n",
    "    #     logger.info(f\"impossible de trouver le fichier {CSV_FILE_PATH}\")\n",
    "    #     df = pd.DataFrame(columns=['id', 'text'])\n",
    "    #     df = df.set_index('id')\n",
    "    #     write_db(df)\n",
    "    #     logger.info(f\"le fichier {CSV_FILE_PATH} a été créé\")\n",
    "\n",
    "    if os.path.exists(DB_FILE_PATH):\n",
    "        logger.info(\"La base de données existe déjà\")\n",
    "    else:\n",
    "        Base.metadata.create_all(bind=engine) \n",
    "        logger.info(f\"Base de données SQL {DB_FILE_PATH} créée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "917abc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-09 10:50:07.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minitialize_db\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1mBase de données SQL c:\\Users\\TIM\\Documents\\Info\\Simplon\\PythonProjet\\FASTAPI\\FAST_API_INITIATION\\DEV\\quotes_db.sql créée\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "initialize_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82e172c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               text\n",
      "id                 \n",
      "1   citation_test_1\n",
      "2   citation_test_2\n"
     ]
    }
   ],
   "source": [
    "print(read_db())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8982200",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(\n",
    "    {\"text\": [\"citation_test_1\", \"citation_test_2\"]},\n",
    "    index=[1,2]\n",
    ")\n",
    "write_db(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_session():\n",
    "#     return session_locale() # permet de créer une session quand on en a besoin\n",
    "# backend/modules/df_tools.py\n",
    "from loguru import logger \n",
    "import pandas as pd\n",
    "import os \n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker, session\n",
    "\n",
    "\n",
    "DB_FILE_PATH = os.path.join(os.getcwd(),\"quotes_db.sql\")\n",
    "engine = create_engine(f\"sqlite:///{DB_FILE_PATH}\", echo=False)\n",
    "session_locale = sessionmaker(bind=engine, autoflush=False, autocommit=False)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "#CSV_FILE_PATH = os.path.join(\"backend\",\"data\", \"quotes_db.csv\")\n",
    "\n",
    "def write_db(df: pd.DataFrame):\n",
    "    #df.to_csv(CSV_FILE_PATH, index=True, index_label='id')\n",
    "    #print(\"write_df\\n\", df)\n",
    "    df.to_sql(\n",
    "        TABLE_NAME,\n",
    "        con=engine,\n",
    "        if_exists='replace', # supprime et remplace la db si deja existante avec la nouvelle db modifiée\n",
    "        index=True,\n",
    "        index_label='id'\n",
    "    )\n",
    "\n",
    "def read_db()->pd.DataFrame:\n",
    "    # df = pd.read_csv(CSV_FILE_PATH, index_col='id')\n",
    "\n",
    "    # if df.isnull().any().any():\n",
    "    #     # raise ValueError(\"Le CSV contient des valeurs nulles\")\n",
    "    #     df_clean = df.dropna()\n",
    "    # for r, c in df.iterrows():\n",
    "    #     print(c.text.isempty)\n",
    "    with get_session() as session:\n",
    "        quotes = session.query(Quote).all() # la liste des objets Quote\n",
    "    Session = session_locale()\n",
    "    try:\n",
    "        quotes = session.query(Quote).all()\n",
    "    finally:\n",
    "        session.close()\n",
    "        \n",
    "    # on veut transformer en dataframe comme dans df_tools \n",
    "    # on parcout la liste quotes\n",
    "    data = [{\"id\": q.id, \"text\": q.text} for q in quotes]\n",
    "    \n",
    "    if not data:\n",
    "        # cas index vide pris en compte\n",
    "        return pd.DataFrame(columns=[\"text\"])\n",
    "    \n",
    "    df = pd.DataFrame(data).set_index(\"id\")\n",
    "\n",
    "    # nettoayge NAN comme dans \n",
    "    for index, row in df.iterrows() : \n",
    "        for col in df.columns:\n",
    "            if pd.isna(row[col]):\n",
    "                logger.info(f\"NaN trouvé à la ligne {index}, colonne '{col}' remplacé par la valeur 'NULL'\")\n",
    "                df.loc[index, col] = \"NULL_REPLACEMENT_VALUE\"\n",
    "    \n",
    "    # print(\"DATA =\", data)\n",
    "    # print(\"COLUMNS =\", df.columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "def initialize_db():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f67a6b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment = sia.polarity_scores(\"bonjour\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f03ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5994}\n"
     ]
    }
   ],
   "source": [
    "sentiment = sia.polarity_scores(\"congratulations\")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8182ae5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     40\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lors de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalyse IA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43manalyse_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtexte\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcongratulations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m, in \u001b[0;36manalyse_sentiment\u001b[1;34m(quote)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/analyse_sentiment/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyse_sentiment\u001b[39m(quote: QuoteIAnalyse):\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\" Recoit un text (anglophone) et renvoie un score de sentiment par IA \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyse du texte: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m         sentiment \u001b[38;5;241m=\u001b[39m sia\u001b[38;5;241m.\u001b[39mpolarity_scores(quote\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field, BaseModel\n",
    "from loguru import logger\n",
    "import os\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "# modèle pydantic\n",
    "class QuoteIAnalyse(BaseModel):\n",
    "    text : str = Field(min_length=1, description=\"donnez un texte pour la citation\")\n",
    "\n",
    "# initialisation de Vader\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "app = FastAPI(title=\"API IA Sentiment\")\n",
    "\n",
    "#création du dossier logs si besoin\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logger.add(\"logs/sentiment_api.log\", rotation=\"500 MB\", level=\"INFO\")\n",
    "\n",
    "\n",
    "@app.post(\"/analyse_sentiment/\")\n",
    "def analyse_sentiment(quote: QuoteIAnalyse):\n",
    "    \"\"\"\" Recoit un text (anglophone) et renvoie un score de sentiment par IA \"\"\"\n",
    "    logger.info(f\"Analyse du texte: {quote.text}\")\n",
    "    try:\n",
    "        sentiment = sia.polarity_scores(quote.text)\n",
    "        logger.info(f\"Resultats IA: {sentiment}\")\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"neg\": sentiment[\"neg\"],\n",
    "            \"neu\": sentiment[\"neu\"],\n",
    "            \"pos\": sentiment[\"pos\"],\n",
    "            \"compound\": sentiment[\"compound\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'analyse IA: {e}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
